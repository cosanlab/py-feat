{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Benchmarking pyfeat Emotion detection algorithms using data\n",
    "*written by Tiankang Xie*  \n",
    "\n",
    "In the tutorial we will demonstrate how to evaluate pyfeat emotion detection algorithms with evaluation data.\n",
    "The evaluative data comes from a subset of affectnet. Please see the csv file inside this tutorial folder for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from feat.utils import set_torch_device\n",
    "import torch.nn.functional as F\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from skimage import draw\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from feat.utils.image_operations import extract_face_from_landmarks\n",
    "\n",
    "from PIL import Image\n",
    "from itertools import product\n",
    "import os \n",
    "from torchvision.transforms import Compose, Normalize, Grayscale\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from feat import Detector\n",
    "\n",
    "from joblib import delayed, Parallel\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.io import read_image, read_video\n",
    "from torch.utils.data import Dataset\n",
    "from feat.transforms import Rescale\n",
    "import glob\n",
    "from skimage.feature import hog\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the path for\n",
    "1. downloaded AffectNet dataset\n",
    "2. where to save the results\n",
    "3. the path to affectnet_testSubset, which can be found inside /py-feat/docs/extra_tutorials/\n",
    "\n",
    "You can request access to AffectNet at http://mohammadmahoor.com/affectnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Storage/Data/AffectNet/Manual_Annot/Manually_Annotated_Images/'\n",
    "save_result_dir = '/Storage/Projects/pyfeat_testing/Data_Eshin/emo_test/'\n",
    "test_file_csv = pd.read_csv('/Storage/Projects/pyfeat_testing/Data_Eshin/emo_test/affectnet_testSubset.csv', index_col=0)\n",
    "inp_fnames = [data_dir + fp for fp in test_file_csv.subDirectory_filePath]\n",
    "test_file_csv['filename'] = test_file_csv.subDirectory_filePath.apply(lambda x: os.path.basename(x).split('.')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Test ResmaskNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiankang/anaconda3/envs/py38/lib/python3.8/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'backbone_name' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/home/tiankang/anaconda3/envs/py38/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "detector = Detector(face_model='retinaface',emotion_model='resmasknet', landmark_model=\"mobilefacenet\", au_model='xgb', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data = []\n",
    "bad_file = 0\n",
    "for inp_name in tqdm(inp_fnames):\n",
    "    try:\n",
    "        img_df = detector.detect_image(input_file_list=inp_name, output_size=None, batch_size=1, num_workers=1)\n",
    "        emo_df = img_df[['anger','disgust','fear','happiness','sadness','surprise','neutral']]\n",
    "        emo_df['filename'] = os.path.basename(inp_name).split('.')[0]\n",
    "        predicted_data.append(emo_df)\n",
    "    except:\n",
    "        bad_file += 1\n",
    "        continue;\n",
    "predicted_data = pd.concat(predicted_data)\n",
    "predicted_data.to_csv(save_result_dir+'resmasknet_bench_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_emo_resmasknet():\n",
    "\n",
    "    emo_categories = ['anger', \"disgust\", \"fear\", \"happiness\", \"sadness\", \"surprise\", \"neutral\"]\n",
    "    a1 = pd.read_csv(save_result_dir+'resmasknet_bench_result.csv', index_col=0)\n",
    "    a2 = pd.merge(a1, test_file_csv, on=['filename'])\n",
    "\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    emo_labels_bi = lb.fit_transform(a2.expression)\n",
    "    emo_preds = np.round(a2[emo_categories])\n",
    "\n",
    "    emo_result = []\n",
    "    for i in range(7):\n",
    "        print('========')\n",
    "        print(emo_categories[i], ' f1 score: ', f1_score(emo_labels_bi[:, i], emo_preds.iloc[:, i]))\n",
    "        emo_result.append(f1_score(emo_labels_bi[:, i], emo_preds.iloc[:, i]))\n",
    "    \n",
    "    arrangement_df_p1 = pd.DataFrame(emo_labels_bi, columns=['anger_label', \"disgust_label\", \"fear_label\", \"happiness_label\", \"sadness_label\", \"surprise_label\", \"neutral_label\"])\n",
    "    arrangement_df_p2 = emo_preds.rename(columns={'anger':'anger_pred', \"disgust\":'disgust_pred', \n",
    "                                                \"fear\": 'fear_pred', \"happiness\":'happiness_pred', \"sadness\":'sadness_pred', \"surprise\":'surprise_pred', \"neutral\":'neutral_pred'})\n",
    "    arrangement_df = pd.concat((arrangement_df_p1, arrangement_df_p2), 1)\n",
    "\n",
    "    return emo_result, arrangement_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating metrics in F1 scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmn_result, rmn_individuals = test_emo_resmasknet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = Detector(face_model='retinaface',emotion_model='svm', landmark_model=\"mobilefacenet\", au_model='xgb', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data = []\n",
    "for inp_name in tqdm(inp_fnames):\n",
    "    try:\n",
    "        eye_df = detector.detect_image(input_file_list=inp_name, output_size=None, batch_size=1, num_workers=1)\n",
    "        eye_new_df = eye_df[['anger','disgust','fear','happiness','sadness','surprise','neutral']]\n",
    "        eye_new_df['filename'] = os.path.basename(inp_name).split('.')[0]\n",
    "        predicted_data.append(eye_new_df)\n",
    "    except:\n",
    "        continue;\n",
    "        \n",
    "predicted_data = pd.concat(predicted_data)\n",
    "predicted_data.to_csv(save_result_dir+'svm_bench_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_svm_resmasknet():\n",
    "\n",
    "    a1 = pd.read_csv(save_result_dir+'svm_bench_result.csv', index_col=0)\n",
    "    a2 = pd.merge(a1, test_file_csv, on=['filename'])\n",
    "\n",
    "    emo_categories = ['anger', \"disgust\", \"fear\", \"happiness\", \"sadness\", \"surprise\", \"neutral\"]\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    emo_labels_bi = lb.fit_transform(a2.expression)\n",
    "    emo_preds = np.round(a2[emo_categories])\n",
    "\n",
    "    emo_result = []\n",
    "    for i in range(7):\n",
    "        print('========')\n",
    "        print(emo_categories[i], ' f1 score: ', f1_score(emo_labels_bi[:, i], emo_preds.iloc[:, i]))\n",
    "        emo_result.append(f1_score(emo_labels_bi[:, i], emo_preds.iloc[:, i]))\n",
    "    \n",
    "    arrangement_df_p1 = pd.DataFrame(emo_labels_bi, columns=['anger_label', \"disgust_label\", \"fear_label\", \"happiness_label\", \"sadness_label\", \"surprise_label\", \"neutral_label\"])\n",
    "    arrangement_df_p2 = emo_preds.rename(columns={'anger':'anger_pred', \"disgust\":'disgust_pred', \n",
    "                                                \"fear\": 'fear_pred', \"happiness\":'happiness_pred', \"sadness\":'sadness_pred', \"surprise\":'surprise_pred', \"neutral\":'neutral_pred'})\n",
    "    arrangement_df = pd.concat((arrangement_df_p1, arrangement_df_p2), 1)\n",
    "\n",
    "    return emo_result, arrangement_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating metrics in F1 scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_result, svm_individuals = test_svm_resmasknet()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd7bcfec4abeaf4c0b67da4b2abbe2cc9cfff96bfbc786c14907766625852b02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
