{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Benchmarking Landmark models using data\n",
    "*written by Tiankang Xie*  \n",
    "\n",
    "In the tutorial we will demonstrate how to evaluate pyfeat landmark detection algorithms with evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from feat import Detector\n",
    "import pickle\n",
    "import os \n",
    "from feat.data import (\n",
    "    Fex,\n",
    "    ImageDataset,\n",
    "    VideoDataset,\n",
    "    _inverse_face_transform,\n",
    "    _inverse_landmark_transform,\n",
    ")\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide the following code for evaluating the normalized mean squared error for landmark detection algorithms. These codes have been slightly modified from: https://github.com/D-X-Y/landmark-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kpts(file_path, num_kpts = 68):\n",
    "    \"\"\"\n",
    "    Function to read the ground truth landmark labels in 300W\n",
    "    \"\"\"\n",
    "    kpts = []\n",
    "    f = open(file_path, 'r')\n",
    "    ln = f.readline()\n",
    "    while not ln.startswith('n_points'):\n",
    "        ln = f.readline()\n",
    "\n",
    "    num_pts = ln.split(':')[1]\n",
    "    num_pts = num_pts.strip('\\n').strip(' ')\n",
    "    # checking for the number of keypoints\n",
    "    if float(num_pts) != num_kpts:\n",
    "        print (\"encountered file with less than keypoints\")\n",
    "        return None\n",
    "\n",
    "    # skipping the line with '{'\n",
    "    ln = f.readline()\n",
    "\n",
    "    ln = f.readline()\n",
    "    while not ln.startswith('}'):\n",
    "        vals = ln.split(' ')[:2]\n",
    "        vals = [v.strip('\\n') for v in vals]\n",
    "        vals = [np.float32(v) for v in vals]\n",
    "        kpts.append(vals)\n",
    "        ln = f.readline()\n",
    "    return kpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(result_dir, data_dir):\n",
    "    \"\"\"\n",
    "    Function to calculate MSE between predicted and groundtruth land labels\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(result_dir, 'rb') as fp:\n",
    "        lands, all_img_dir = pickle.load(fp)    \n",
    "\n",
    "    paths_errors = []\n",
    "    for i, land_paths in enumerate(all_img_dir):\n",
    "        land = lands[i]\n",
    "        condition = os.path.basename(land_paths).split('_')[0]\n",
    "        if condition == 'indoor':\n",
    "            kpts = get_kpts(data_dir+'01_Indoor/'+os.path.basename(land_paths).replace('png','pts'))\n",
    "            GT_points = np.asarray(kpts)\n",
    "        elif condition == 'outdoor':\n",
    "            kpts = get_kpts(data_dir+'02_Outdoor/'+os.path.basename(land_paths).replace('png','pts'))\n",
    "            GT_points = np.asarray(kpts)\n",
    "        else:\n",
    "            raise ValueError('weird happened')\n",
    "        \n",
    "        interocular_distance = np.linalg.norm(GT_points[36,:]-GT_points[45,:], ord=2)\n",
    "        ans_diff = []\n",
    "        for llnd in land[0]:\n",
    "            summ = np.linalg.norm(GT_points - llnd, ord=2, axis=0)\n",
    "            ans_diff.append(summ/(68*interocular_distance)) # normalize with interocular distance\n",
    "            # ans_diff.append(np.sqrt(np.mean(np.square(GT_points - llnd))))\n",
    "        paths_errors.append(np.min(ans_diff)*10)\n",
    "\n",
    "    return np.mean(paths_errors)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the path for \n",
    "1. data and labels. Which can be found at https://ibug.doc.ic.ac.uk/resources/300-W/\n",
    "2. where to save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Storage/Data/300W/'\n",
    "save_result_dir = '/Storage/Projects/pyfeat_testing/Data_Eshin/land_test/'\n",
    "all_img_dir = glob.glob(data_dir + '01_Indoor/*.png') + glob.glob(data_dir + '02_Outdoor/*.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "chosen_model = 'mobilenet'\n",
    "detector = Detector(face_model='retinaface',emotion_model='resmasknet', landmark_model=chosen_model, au_model='xgb', device='cpu')\n",
    "\n",
    "counter = 0\n",
    "lands = []\n",
    "for fp in tqdm(all_img_dir):\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        ImageDataset(\n",
    "            fp,\n",
    "            output_size=None,\n",
    "            preserve_aspect_ratio=True,\n",
    "            padding=True,\n",
    "        ),\n",
    "        num_workers=1,\n",
    "        batch_size=1,\n",
    "        pin_memory=False,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    batch_output = []\n",
    "    for batch_id, batch_data in enumerate(tqdm(data_loader)):\n",
    "        faces = detector.detect_faces(batch_data[\"Image\"])\n",
    "        landmarks = detector.detect_landmarks(batch_data[\"Image\"], detected_faces=faces)\n",
    "    lands.append(landmarks)\n",
    "\n",
    "# Save Result\n",
    "with open(save_result_dir+f'{chosen_model}_bench_results.pkl', 'wb') as fp:\n",
    "    pickle.dump((lands, all_img_dir), fp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_normal = calculate_rmse(result_dir=save_result_dir+'mobilenet_bench_results.pkl', data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized mean squared error for the algorithm is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.769516086484791\n"
     ]
    }
   ],
   "source": [
    "print(mobilenet_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of MobileFaceNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "chosen_model = 'mobilefacenet'\n",
    "detector = Detector(face_model='retinaface',emotion_model='resmasknet', landmark_model=chosen_model, au_model='xgb', device='cpu')\n",
    "\n",
    "counter = 0\n",
    "lands = []\n",
    "for fp in tqdm(all_img_dir):\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        ImageDataset(\n",
    "            fp,\n",
    "            output_size=None,\n",
    "            preserve_aspect_ratio=True,\n",
    "            padding=True,\n",
    "        ),\n",
    "        num_workers=1,\n",
    "        batch_size=1,\n",
    "        pin_memory=False,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    batch_output = []\n",
    "    for batch_id, batch_data in enumerate(tqdm(data_loader)):\n",
    "        faces = detector.detect_faces(batch_data[\"Image\"])\n",
    "        landmarks = detector.detect_landmarks(batch_data[\"Image\"], detected_faces=faces)\n",
    "    lands.append(landmarks)\n",
    "\n",
    "# Save Result\n",
    "with open(save_result_dir+f'{chosen_model}_bench_results.pkl', 'wb') as fp:\n",
    "    pickle.dump((lands, all_img_dir), fp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilefacenet_normal = calculate_rmse(result_dir=save_result_dir+f'{chosen_model}_bench_results.pkl', data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized mean squared error for the algorithm is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.988652327582802\n"
     ]
    }
   ],
   "source": [
    "print(mobilefacenet_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of PFLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "chosen_model = 'pfld'\n",
    "detector = Detector(face_model='retinaface',emotion_model='resmasknet', landmark_model=chosen_model, au_model='xgb', device='cpu')\n",
    "\n",
    "counter = 0\n",
    "lands = []\n",
    "for fp in tqdm(all_img_dir):\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        ImageDataset(\n",
    "            fp,\n",
    "            output_size=None,\n",
    "            preserve_aspect_ratio=True,\n",
    "            padding=True,\n",
    "        ),\n",
    "        num_workers=1,\n",
    "        batch_size=1,\n",
    "        pin_memory=False,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    batch_output = []\n",
    "    for batch_id, batch_data in enumerate(tqdm(data_loader)):\n",
    "        faces = detector.detect_faces(batch_data[\"Image\"])\n",
    "        landmarks = detector.detect_landmarks(batch_data[\"Image\"], detected_faces=faces)\n",
    "    lands.append(landmarks)\n",
    "\n",
    "# Save Result\n",
    "with open(save_result_dir+f'{chosen_model}_bench_results.pkl', 'wb') as fp:\n",
    "    pickle.dump((lands, all_img_dir), fp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfld_normal = calculate_rmse(result_dir=save_result_dir+'pfld_bench_results.pkl', data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized mean squared error for the algorithm is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.390958738782998\n"
     ]
    }
   ],
   "source": [
    "print(pfld_normal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb973b375f2d280323e3fea5f1f02d1878ea0342ecfe5636a4609970d8a89fff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
