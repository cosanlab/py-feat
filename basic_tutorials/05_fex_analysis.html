
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>5. Running a full analysis &#8212; Py-Feat</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="6. Training an AU visualization model" href="../extra_tutorials/06_trainAUvisModel.html" />
    <link rel="prev" title="4. Visualizing Facial Expressions" href="04_plotting.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/pyfeat_logo_small.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Py-Feat</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../pages/intro.html">
                    Py-Feat: Python Facial Expression Analysis Toolbox
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting Started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../pages/installation.html">
   How to install Py-Feat
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pages/models.html">
   Included pre-trained detectors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pages/au_reference.html">
   Action Unit Reference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pages/usage_guide.html">
   Tips, Community, and Known Issues
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Basic Tutorials
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_basics.html">
   1. Py-Feat basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_detector_imgs.html">
   2. Detecting facial expressions from images
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_detector_vids.html">
   3. Detecting facial expressions from videos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_plotting.html">
   4. Visualizing Facial Expressions
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   5. Running a full analysis
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Advanced Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../extra_tutorials/06_trainAUvisModel.html">
   6. Training an AU visualization model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../extra_tutorials/07_extract_labels_and_landmarks.html">
   7. Example labels and landmark dataset loading
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../extra_tutorials/08_train_hogs.html">
   8. Training HOG-based AU detectors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../extra_tutorials/09_test_bbox.html">
   9. Benchmarking Bounding Box using data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../extra_tutorials/10_test_lands.html">
   10. Benchmarking Landmark models using data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../extra_tutorials/11_test_Poseinfo.html">
   11. Benchmarking Pose detectors using data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../extra_tutorials/12_test_aus.html">
   12. Benchmarking Action Unit detector using data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../extra_tutorials/13_test_emos.html">
   13. Benchmarking pyfeat Emotion detection algorithms using data
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  API
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../pages/api.html">
   API Reference
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Contributing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../pages/contribute.html">
   General contributions guidelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pages/modelContribution.html">
   Contributing new detectors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pages/changelog.html">
   Change Log
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/cosanlab/py-feat">
   GitHub Repository
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/cosanlab/py-feat/master?urlpath=tree/notebooks/basic_tutorials/05_fex_analysis.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://jhub.dartmouth.edu/hub/user-redirect/git-pull?repo=https%3A//github.com/cosanlab/py-feat&urlpath=tree/py-feat/notebooks/basic_tutorials/05_fex_analysis.ipynb&branch=master"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on JupyterHub"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_jupyterhub.svg">
  </span>
<span class="headerbtn__text-container">JupyterHub</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/cosanlab/py-feat/blob/master/notebooks/basic_tutorials/05_fex_analysis.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/cosanlab/py-feat"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/cosanlab/py-feat/issues/new?title=Issue%20on%20page%20%2Fbasic_tutorials/05_fex_analysis.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/basic_tutorials/05_fex_analysis.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   5. Running a full analysis
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#download-the-data">
   5.1 Download the data
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extract-facial-features-using-detector">
   5.2 Extract facial features using
   <code class="docutils literal notranslate">
    <span class="pre">
     Detector
    </span>
   </code>
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#aggregate-detections-using-a-fex-dataframe">
   5.3. Aggregate detections using a
   <code class="docutils literal notranslate">
    <span class="pre">
     Fex
    </span>
   </code>
   dataframe
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summarize-data-with-fex-sessions">
     5.3.1 Summarize data with
     <code class="docutils literal notranslate">
      <span class="pre">
       Fex.sessions
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#chaining-operations">
     5.3.2 Chaining operations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#comparing-the-condition-difference-across-aus-using-regression">
   5.4 Comparing the condition difference across AUs using regression
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#decoding-condition-from-facial-features">
   5.5 Decoding condition from facial features
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualizing-decoder-weights">
     5.5.1 Visualizing decoder weights
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#time-series-analysis">
   5.6 Time-series analysis
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>5. Running a full analysis</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   5. Running a full analysis
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#download-the-data">
   5.1 Download the data
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extract-facial-features-using-detector">
   5.2 Extract facial features using
   <code class="docutils literal notranslate">
    <span class="pre">
     Detector
    </span>
   </code>
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#aggregate-detections-using-a-fex-dataframe">
   5.3. Aggregate detections using a
   <code class="docutils literal notranslate">
    <span class="pre">
     Fex
    </span>
   </code>
   dataframe
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summarize-data-with-fex-sessions">
     5.3.1 Summarize data with
     <code class="docutils literal notranslate">
      <span class="pre">
       Fex.sessions
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#chaining-operations">
     5.3.2 Chaining operations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#comparing-the-condition-difference-across-aus-using-regression">
   5.4 Comparing the condition difference across AUs using regression
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#decoding-condition-from-facial-features">
   5.5 Decoding condition from facial features
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualizing-decoder-weights">
     5.5.1 Visualizing decoder weights
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#time-series-analysis">
   5.6 Time-series analysis
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="running-a-full-analysis">
<h1>5. Running a full analysis<a class="headerlink" href="#running-a-full-analysis" title="Permalink to this headline">#</a></h1>
<p><em>Written by Jin Hyun Cheong and Eshin Jolly</em></p>
<p>In this tutorial we’ll perform a real analysis on part of the open dataset from <a class="reference external" href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008335">“A Data-Driven Characterisation Of Natural Facial Expressions When Giving Good And Bad News”</a> by Watson &amp; Johnston 2020.  You can try it out interactively in Google Collab: <a class="reference external" href="https://colab.research.google.com/github/cosanlab/py-feat/blob/master/notebooks/content/04_fex_analysis.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<p>In the original paper the authors had 3 speakers deliver <em>good</em> or <em>bad</em> news while filming their facial expressions. They found that could accurately “decode” each condition based on participants’ facial expressions extracted either using a custom multi-chanel-gradient model or action units (AUs) extracted using <a class="reference external" href="https://github.com/TadasBaltrusaitis/OpenFace">Open Face</a>.</p>
<p>In this tutorial we’ll show how easiy it is to not only reproduce their decoding analysis with py-feat, but just as easily perform additional analyses. Specifically we’ll:</p>
<ol class="simple">
<li><p>Download 20 of the first subject’s videos (the full dataset is available on <a class="reference external" href="https://osf.io/6tbwj/">OSF</a></p></li>
<li><p>Extract facial features using the <code class="docutils literal notranslate"><span class="pre">Detector</span></code></p></li>
<li><p>Aggregate and summarize detections per video using <code class="docutils literal notranslate"><span class="pre">Fex</span></code></p></li>
<li><p>Train and test a decoder to classify <em>good</em> vs <em>bad</em> news using extracted emotions, AUs, and poses</p></li>
<li><p>Run a fMRI style “mass-univariate” comparison across all AUs between conditions</p></li>
<li><p>Run a time-series analysis comparing videos based on the time-courses of extracted facial fatures</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Uncomment the line below and run this only if you&#39;re using Google Collab
# !pip install -q py-feat
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="download-the-data">
<h1>5.1 Download the data<a class="headerlink" href="#download-the-data" title="Permalink to this headline">#</a></h1>
<p>Here’s we’ll download and save the first 20 video files and their corresponding attributes from OSF. The next cell should run quickly on Google Collab, but will depend on your own internet conection if you’re executing this notebook locally. You can rerun this cell in case the download fails for any reason, as it should skip downloading existing files:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import os
import subprocess
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from glob import glob
import seaborn as sns
from tqdm import tqdm
sns.set_context(&quot;talk&quot;)

files_to_download = {
    &quot;4c5mb&quot;: &#39;clip_attrs.csv&#39;,
    &quot;n6rt3&quot;: &#39;001.mp4&#39;,
    &quot;3gh8v&quot;: &#39;002.mp4&#39;,
    &quot;twqxs&quot;: &#39;003.mp4&#39;,
    &quot;nc7d9&quot;: &#39;004.mp4&#39;,
    &quot;nrwcm&quot;: &#39;005.mp4&#39;,
    &quot;2rk9c&quot;: &#39;006.mp4&#39;,
    &quot;mxkzq&quot;: &#39;007.mp4&#39;,
    &quot;c2na7&quot;: &#39;008.mp4&#39;,
    &quot;wj7zy&quot;: &#39;009.mp4&#39;,
    &quot;mxywn&quot;: &#39;010.mp4&#39;,
    &quot;6bn3g&quot;: &#39;011.mp4&#39;,
    &quot;jkwsp&quot;: &#39;012.mp4&#39;,
    &quot;54gtv&quot;: &#39;013.mp4&#39;,
    &quot;c3hpm&quot;: &#39;014.mp4&#39;,
    &quot;utdqj&quot;: &#39;015.mp4&#39;,
    &quot;hpw4a&quot;: &#39;016.mp4&#39;,
    &quot;94swe&quot;: &#39;017.mp4&#39;,
    &quot;qte5y&quot;: &#39;018.mp4&#39;,
    &quot;aykvu&quot;: &#39;019.mp4&#39;,
    &quot;3d5ry&quot;: &#39;020.mp4&#39;,
}

for fid, fname in files_to_download.items():
    if not os.path.exists(fname):
        print(f&quot;Downloading: {fname}&quot;)
        subprocess.run(f&quot;wget -O {fname} --content-disposition https://osf.io/{fid}/download&quot;.split())

videos = np.sort(glob(&quot;*.mp4&quot;))

# Load in attributes
clip_attrs = pd.read_csv(&quot;clip_attrs.csv&quot;)

# Add in file names and rename conditions
clip_attrs = clip_attrs.assign(
    input=clip_attrs.clipN.apply(lambda x: str(x).zfill(3) + &quot;.mp4&quot;),
    condition=clip_attrs[&quot;class&quot;].replace({&quot;gn&quot;: &quot;goodNews&quot;, &quot;ists&quot;: &quot;badNews&quot;}),
)

# We&#39;re only using a subset of videos for this tutorial so drop the rest
clip_attrs = clip_attrs.query(&quot;input in @videos&quot;)

print(f&quot;Downloaded {len(videos)} videos&quot;)
print(f&quot;Downloaded attributes files with {clip_attrs.shape[0]} rows&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloaded 20 videos
Downloaded attributes files with 20 rows
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="extract-facial-features-using-detector">
<h1>5.2 Extract facial features using <code class="docutils literal notranslate"><span class="pre">Detector</span></code><a class="headerlink" href="#extract-facial-features-using-detector" title="Permalink to this headline">#</a></h1>
<p>Now we’ll initialize a new <code class="docutils literal notranslate"><span class="pre">Detector</span></code>, process each frame of each video using <code class="docutils literal notranslate"><span class="pre">.detect_video()</span></code>, and save the results to csv files named after the video.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from feat import Detector

# Initialize the default detector
detector = Detector()

# Loop over and process each video and save results to csv
for video in tqdm(videos):
    out_name = video.replace(&quot;.mp4&quot;, &quot;.csv&quot;)
    if not os.path.exists(out_name):

        print(f&quot;Processing: {video}&quot;)

        # This is the line that does detection!
        fex = detector.detect_video(video)

        fex.to_csv(out_name, index=False)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 20/20 [00:00&lt;00:00, 9074.65it/s]
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="aggregate-detections-using-a-fex-dataframe">
<h1>5.3. Aggregate detections using a <code class="docutils literal notranslate"><span class="pre">Fex</span></code> dataframe<a class="headerlink" href="#aggregate-detections-using-a-fex-dataframe" title="Permalink to this headline">#</a></h1>
<p>Then we can use <code class="docutils literal notranslate"><span class="pre">read_feat</span></code> to load each CSV file and concatenate them together:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from feat.utils.io import read_feat

fex = pd.concat(map(lambda video: read_feat(video.replace(&quot;.mp4&quot;, &quot;.csv&quot;)), videos))

print(f&quot;Unique videos: {fex.inputs.nunique()}&quot;)
print(f&quot;Total processed frames: {fex.shape[0]}&quot;)
print(f&quot;Avg frames per video: {fex.groupby(&#39;input&#39;).size().mean()}&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Unique videos: 20
Total processed frames: 947
Avg frames per video: 47.35
</pre></div>
</div>
</div>
</div>
<p>Our <code class="docutils literal notranslate"><span class="pre">Fex</span></code> dataframe now contains all detections for all frames of each video</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fex.shape
fex.head()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(947, 173)
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>FaceRectX</th>
      <th>FaceRectY</th>
      <th>FaceRectWidth</th>
      <th>FaceRectHeight</th>
      <th>FaceScore</th>
      <th>x_0</th>
      <th>x_1</th>
      <th>x_2</th>
      <th>x_3</th>
      <th>x_4</th>
      <th>...</th>
      <th>AU43</th>
      <th>anger</th>
      <th>disgust</th>
      <th>fear</th>
      <th>happiness</th>
      <th>sadness</th>
      <th>surprise</th>
      <th>neutral</th>
      <th>input</th>
      <th>frame</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>236.153809</td>
      <td>182.587204</td>
      <td>254.930786</td>
      <td>349.109451</td>
      <td>0.999326</td>
      <td>355.590267</td>
      <td>361.166635</td>
      <td>370.024031</td>
      <td>382.002333</td>
      <td>405.379242</td>
      <td>...</td>
      <td>0.017959</td>
      <td>0.000438</td>
      <td>0.000117</td>
      <td>0.000483</td>
      <td>0.981574</td>
      <td>0.001495</td>
      <td>0.013396</td>
      <td>0.002497</td>
      <td>001.csv</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>236.198212</td>
      <td>182.582245</td>
      <td>254.905151</td>
      <td>349.177582</td>
      <td>0.999327</td>
      <td>355.947047</td>
      <td>361.429636</td>
      <td>370.189673</td>
      <td>382.098332</td>
      <td>405.381871</td>
      <td>...</td>
      <td>0.031311</td>
      <td>0.000422</td>
      <td>0.000110</td>
      <td>0.000471</td>
      <td>0.981490</td>
      <td>0.001407</td>
      <td>0.013663</td>
      <td>0.002437</td>
      <td>001.csv</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>237.683929</td>
      <td>181.546631</td>
      <td>254.771271</td>
      <td>349.269104</td>
      <td>0.999371</td>
      <td>357.488551</td>
      <td>363.557662</td>
      <td>372.905629</td>
      <td>385.126006</td>
      <td>408.333512</td>
      <td>...</td>
      <td>0.022510</td>
      <td>0.000379</td>
      <td>0.000112</td>
      <td>0.000329</td>
      <td>0.988872</td>
      <td>0.001477</td>
      <td>0.006877</td>
      <td>0.001954</td>
      <td>001.csv</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>239.606812</td>
      <td>181.352219</td>
      <td>254.592834</td>
      <td>351.001907</td>
      <td>0.999298</td>
      <td>358.248297</td>
      <td>364.062520</td>
      <td>373.173968</td>
      <td>385.128103</td>
      <td>407.907217</td>
      <td>...</td>
      <td>0.040652</td>
      <td>0.000451</td>
      <td>0.000122</td>
      <td>0.000229</td>
      <td>0.989229</td>
      <td>0.001519</td>
      <td>0.005104</td>
      <td>0.003346</td>
      <td>001.csv</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>238.934204</td>
      <td>177.416992</td>
      <td>257.367035</td>
      <td>356.700012</td>
      <td>0.999240</td>
      <td>353.728640</td>
      <td>360.555682</td>
      <td>370.127252</td>
      <td>382.294048</td>
      <td>405.861680</td>
      <td>...</td>
      <td>0.090656</td>
      <td>0.000388</td>
      <td>0.000067</td>
      <td>0.000447</td>
      <td>0.976272</td>
      <td>0.001275</td>
      <td>0.016979</td>
      <td>0.004573</td>
      <td>001.csv</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 173 columns</p>
</div></div></div>
</div>
<section id="summarize-data-with-fex-sessions">
<h2>5.3.1 Summarize data with <code class="docutils literal notranslate"><span class="pre">Fex.sessions</span></code><a class="headerlink" href="#summarize-data-with-fex-sessions" title="Permalink to this headline">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">Fex</span></code> dataframes have a special attribute called <code class="docutils literal notranslate"><span class="pre">.sessions</span></code> that act as a grouping factor to make it easier to compute summary statistics with any of the <code class="docutils literal notranslate"><span class="pre">.extract_*</span></code> methods. By default <code class="docutils literal notranslate"><span class="pre">.sessions</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>, but you can use the <code class="docutils literal notranslate"><span class="pre">.update_sessions()</span></code> to return <strong>a new Fex dataframe</strong> with <code class="docutils literal notranslate"><span class="pre">.sessions</span></code> set.</p>
<p>For example, if we update the sessions to be the name of each video, then <code class="docutils literal notranslate"><span class="pre">.extract_mean()</span></code> will group video-frames (rows) by video making it easy to compute a single summary statistic per file:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>by_video = fex.update_sessions(fex[&quot;input&quot;])

# Compute the mean per video
video_means = by_video.extract_mean()

video_means # 20 rows for 20 videos
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean_FaceRectX</th>
      <th>mean_FaceRectY</th>
      <th>mean_FaceRectWidth</th>
      <th>mean_FaceRectHeight</th>
      <th>mean_FaceScore</th>
      <th>mean_x_0</th>
      <th>mean_x_1</th>
      <th>mean_x_2</th>
      <th>mean_x_3</th>
      <th>mean_x_4</th>
      <th>...</th>
      <th>mean_AU28</th>
      <th>mean_AU43</th>
      <th>mean_anger</th>
      <th>mean_disgust</th>
      <th>mean_fear</th>
      <th>mean_happiness</th>
      <th>mean_sadness</th>
      <th>mean_surprise</th>
      <th>mean_neutral</th>
      <th>mean_frame</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>001.csv</th>
      <td>234.431216</td>
      <td>179.408653</td>
      <td>253.195079</td>
      <td>349.057933</td>
      <td>0.999415</td>
      <td>351.745947</td>
      <td>358.669057</td>
      <td>369.211596</td>
      <td>382.289621</td>
      <td>405.340749</td>
      <td>...</td>
      <td>0.335354</td>
      <td>0.058032</td>
      <td>0.000840</td>
      <td>0.000170</td>
      <td>0.002119</td>
      <td>0.955028</td>
      <td>0.011139</td>
      <td>0.022887</td>
      <td>0.007818</td>
      <td>19.5</td>
    </tr>
    <tr>
      <th>002.csv</th>
      <td>235.137069</td>
      <td>177.244835</td>
      <td>247.376738</td>
      <td>346.628496</td>
      <td>0.999420</td>
      <td>351.152403</td>
      <td>356.936973</td>
      <td>366.408657</td>
      <td>378.847147</td>
      <td>401.092449</td>
      <td>...</td>
      <td>0.388296</td>
      <td>0.091377</td>
      <td>0.000609</td>
      <td>0.000115</td>
      <td>0.001898</td>
      <td>0.879776</td>
      <td>0.012571</td>
      <td>0.094248</td>
      <td>0.010782</td>
      <td>13.5</td>
    </tr>
    <tr>
      <th>003.csv</th>
      <td>231.095030</td>
      <td>175.658435</td>
      <td>251.547485</td>
      <td>351.115814</td>
      <td>0.999401</td>
      <td>342.375212</td>
      <td>346.903972</td>
      <td>354.548829</td>
      <td>365.250301</td>
      <td>386.696666</td>
      <td>...</td>
      <td>0.144093</td>
      <td>0.047709</td>
      <td>0.000355</td>
      <td>0.000061</td>
      <td>0.001733</td>
      <td>0.707242</td>
      <td>0.001066</td>
      <td>0.285287</td>
      <td>0.004256</td>
      <td>23.0</td>
    </tr>
    <tr>
      <th>004.csv</th>
      <td>220.796929</td>
      <td>176.294354</td>
      <td>252.812039</td>
      <td>353.827636</td>
      <td>0.999425</td>
      <td>328.644936</td>
      <td>334.260224</td>
      <td>342.829941</td>
      <td>354.501717</td>
      <td>376.853730</td>
      <td>...</td>
      <td>0.147945</td>
      <td>0.099202</td>
      <td>0.000721</td>
      <td>0.000068</td>
      <td>0.001341</td>
      <td>0.847641</td>
      <td>0.012390</td>
      <td>0.132939</td>
      <td>0.004900</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>005.csv</th>
      <td>208.867616</td>
      <td>189.404122</td>
      <td>255.296208</td>
      <td>349.989491</td>
      <td>0.999394</td>
      <td>312.148711</td>
      <td>317.922322</td>
      <td>327.292733</td>
      <td>339.933222</td>
      <td>363.364786</td>
      <td>...</td>
      <td>0.199008</td>
      <td>0.078288</td>
      <td>0.000226</td>
      <td>0.000043</td>
      <td>0.000490</td>
      <td>0.986752</td>
      <td>0.001082</td>
      <td>0.009684</td>
      <td>0.001723</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>006.csv</th>
      <td>228.037525</td>
      <td>170.552953</td>
      <td>248.412705</td>
      <td>350.898739</td>
      <td>0.999457</td>
      <td>339.691768</td>
      <td>343.841731</td>
      <td>351.142231</td>
      <td>361.316873</td>
      <td>382.081545</td>
      <td>...</td>
      <td>0.205943</td>
      <td>0.046411</td>
      <td>0.000246</td>
      <td>0.000036</td>
      <td>0.000628</td>
      <td>0.941467</td>
      <td>0.001282</td>
      <td>0.054525</td>
      <td>0.001816</td>
      <td>23.5</td>
    </tr>
    <tr>
      <th>007.csv</th>
      <td>232.329588</td>
      <td>173.086361</td>
      <td>249.666888</td>
      <td>349.413313</td>
      <td>0.999380</td>
      <td>345.372773</td>
      <td>348.641482</td>
      <td>355.122228</td>
      <td>364.639966</td>
      <td>384.731837</td>
      <td>...</td>
      <td>0.109040</td>
      <td>0.069314</td>
      <td>0.000374</td>
      <td>0.000058</td>
      <td>0.002243</td>
      <td>0.933058</td>
      <td>0.003285</td>
      <td>0.057281</td>
      <td>0.003701</td>
      <td>13.0</td>
    </tr>
    <tr>
      <th>008.csv</th>
      <td>217.474341</td>
      <td>174.956181</td>
      <td>252.330176</td>
      <td>351.949308</td>
      <td>0.999335</td>
      <td>322.590086</td>
      <td>328.698168</td>
      <td>337.769330</td>
      <td>348.969558</td>
      <td>369.878785</td>
      <td>...</td>
      <td>0.293920</td>
      <td>0.046400</td>
      <td>0.000327</td>
      <td>0.000091</td>
      <td>0.004953</td>
      <td>0.592064</td>
      <td>0.003459</td>
      <td>0.393644</td>
      <td>0.005462</td>
      <td>17.5</td>
    </tr>
    <tr>
      <th>009.csv</th>
      <td>221.263109</td>
      <td>167.619245</td>
      <td>249.194669</td>
      <td>355.021916</td>
      <td>0.999307</td>
      <td>328.585905</td>
      <td>334.560713</td>
      <td>343.619836</td>
      <td>355.424001</td>
      <td>377.394425</td>
      <td>...</td>
      <td>0.262887</td>
      <td>0.044629</td>
      <td>0.000317</td>
      <td>0.000195</td>
      <td>0.014244</td>
      <td>0.536781</td>
      <td>0.003003</td>
      <td>0.442032</td>
      <td>0.003427</td>
      <td>20.5</td>
    </tr>
    <tr>
      <th>010.csv</th>
      <td>227.248687</td>
      <td>184.991356</td>
      <td>248.113907</td>
      <td>348.310015</td>
      <td>0.999450</td>
      <td>336.439669</td>
      <td>342.711365</td>
      <td>352.625989</td>
      <td>365.147914</td>
      <td>388.132257</td>
      <td>...</td>
      <td>0.252469</td>
      <td>0.041731</td>
      <td>0.000243</td>
      <td>0.000051</td>
      <td>0.005075</td>
      <td>0.691970</td>
      <td>0.008150</td>
      <td>0.290069</td>
      <td>0.004443</td>
      <td>26.5</td>
    </tr>
    <tr>
      <th>011.csv</th>
      <td>222.215382</td>
      <td>209.882381</td>
      <td>246.810548</td>
      <td>348.319372</td>
      <td>0.999462</td>
      <td>317.001702</td>
      <td>329.615415</td>
      <td>347.071755</td>
      <td>367.541387</td>
      <td>397.147639</td>
      <td>...</td>
      <td>0.236520</td>
      <td>0.022382</td>
      <td>0.130460</td>
      <td>0.007293</td>
      <td>0.067473</td>
      <td>0.134826</td>
      <td>0.119239</td>
      <td>0.239828</td>
      <td>0.300882</td>
      <td>17.5</td>
    </tr>
    <tr>
      <th>012.csv</th>
      <td>224.773651</td>
      <td>223.677334</td>
      <td>243.875583</td>
      <td>341.147256</td>
      <td>0.999400</td>
      <td>321.367646</td>
      <td>334.862112</td>
      <td>352.977879</td>
      <td>374.908646</td>
      <td>405.053755</td>
      <td>...</td>
      <td>0.168390</td>
      <td>0.171352</td>
      <td>0.002793</td>
      <td>0.001974</td>
      <td>0.073120</td>
      <td>0.066317</td>
      <td>0.176804</td>
      <td>0.657999</td>
      <td>0.020993</td>
      <td>23.5</td>
    </tr>
    <tr>
      <th>013.csv</th>
      <td>229.422940</td>
      <td>188.842976</td>
      <td>246.955987</td>
      <td>350.861501</td>
      <td>0.999402</td>
      <td>341.007234</td>
      <td>351.553327</td>
      <td>365.335356</td>
      <td>382.232456</td>
      <td>408.826613</td>
      <td>...</td>
      <td>0.305139</td>
      <td>0.027319</td>
      <td>0.001247</td>
      <td>0.000341</td>
      <td>0.027139</td>
      <td>0.025583</td>
      <td>0.140288</td>
      <td>0.772149</td>
      <td>0.033251</td>
      <td>13.5</td>
    </tr>
    <tr>
      <th>014.csv</th>
      <td>226.500757</td>
      <td>180.036496</td>
      <td>245.309567</td>
      <td>352.485154</td>
      <td>0.999373</td>
      <td>326.507088</td>
      <td>338.703004</td>
      <td>355.255419</td>
      <td>375.844798</td>
      <td>405.824674</td>
      <td>...</td>
      <td>0.125695</td>
      <td>0.031951</td>
      <td>0.004123</td>
      <td>0.002852</td>
      <td>0.259469</td>
      <td>0.000338</td>
      <td>0.242996</td>
      <td>0.452750</td>
      <td>0.037473</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>015.csv</th>
      <td>221.191514</td>
      <td>194.450694</td>
      <td>244.257210</td>
      <td>350.411649</td>
      <td>0.999404</td>
      <td>318.571982</td>
      <td>329.832546</td>
      <td>345.395775</td>
      <td>364.710552</td>
      <td>393.250724</td>
      <td>...</td>
      <td>0.149373</td>
      <td>0.102222</td>
      <td>0.001375</td>
      <td>0.000311</td>
      <td>0.195097</td>
      <td>0.003530</td>
      <td>0.434903</td>
      <td>0.350142</td>
      <td>0.014644</td>
      <td>29.0</td>
    </tr>
    <tr>
      <th>016.csv</th>
      <td>201.787207</td>
      <td>188.279645</td>
      <td>248.485522</td>
      <td>345.852839</td>
      <td>0.999459</td>
      <td>297.753369</td>
      <td>309.231162</td>
      <td>324.626972</td>
      <td>343.137091</td>
      <td>370.771578</td>
      <td>...</td>
      <td>0.302705</td>
      <td>0.028967</td>
      <td>0.002659</td>
      <td>0.001119</td>
      <td>0.053669</td>
      <td>0.005470</td>
      <td>0.150112</td>
      <td>0.737356</td>
      <td>0.049615</td>
      <td>38.5</td>
    </tr>
    <tr>
      <th>017.csv</th>
      <td>215.591319</td>
      <td>195.263961</td>
      <td>246.963525</td>
      <td>342.558035</td>
      <td>0.999355</td>
      <td>323.741976</td>
      <td>329.358193</td>
      <td>338.566349</td>
      <td>351.548930</td>
      <td>373.243177</td>
      <td>...</td>
      <td>0.192169</td>
      <td>0.035812</td>
      <td>0.000944</td>
      <td>0.000358</td>
      <td>0.061095</td>
      <td>0.006041</td>
      <td>0.050949</td>
      <td>0.866098</td>
      <td>0.014514</td>
      <td>28.0</td>
    </tr>
    <tr>
      <th>018.csv</th>
      <td>229.367711</td>
      <td>186.727653</td>
      <td>246.125126</td>
      <td>352.387675</td>
      <td>0.999429</td>
      <td>328.829019</td>
      <td>337.406731</td>
      <td>350.572361</td>
      <td>368.037250</td>
      <td>395.964752</td>
      <td>...</td>
      <td>0.149709</td>
      <td>0.030375</td>
      <td>0.007092</td>
      <td>0.002789</td>
      <td>0.155484</td>
      <td>0.012824</td>
      <td>0.175173</td>
      <td>0.519115</td>
      <td>0.127522</td>
      <td>26.5</td>
    </tr>
    <tr>
      <th>019.csv</th>
      <td>203.091716</td>
      <td>183.023964</td>
      <td>253.458237</td>
      <td>352.042444</td>
      <td>0.999275</td>
      <td>303.143011</td>
      <td>310.439069</td>
      <td>321.088562</td>
      <td>334.650816</td>
      <td>358.007455</td>
      <td>...</td>
      <td>0.383015</td>
      <td>0.036445</td>
      <td>0.000663</td>
      <td>0.000140</td>
      <td>0.116914</td>
      <td>0.000767</td>
      <td>0.374723</td>
      <td>0.490313</td>
      <td>0.016481</td>
      <td>31.5</td>
    </tr>
    <tr>
      <th>020.csv</th>
      <td>196.402858</td>
      <td>186.635690</td>
      <td>250.095409</td>
      <td>339.914147</td>
      <td>0.999489</td>
      <td>293.626183</td>
      <td>302.517683</td>
      <td>314.678548</td>
      <td>329.424593</td>
      <td>353.108089</td>
      <td>...</td>
      <td>0.346318</td>
      <td>0.040663</td>
      <td>0.000776</td>
      <td>0.000236</td>
      <td>0.086137</td>
      <td>0.014581</td>
      <td>0.059977</td>
      <td>0.822615</td>
      <td>0.015677</td>
      <td>32.5</td>
    </tr>
  </tbody>
</table>
<p>20 rows × 172 columns</p>
</div></div></div>
</div>
<p>Then we can grab the AU detections and call standard pandas methods like <code class="docutils literal notranslate"><span class="pre">.loc</span></code> and <code class="docutils literal notranslate"><span class="pre">.plot</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Grab the aus just for video 1
video001_aus = video_means.aus.loc[&#39;001.csv&#39;]

# Plot them
ax = video001_aus.plot(kind=&#39;bar&#39;, title=&#39;Video 001 AU detection&#39;);
ax.set(ylabel=&#39;Average Probability&#39;);
sns.despine();
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/05_fex_analysis_14_0.png" src="../_images/05_fex_analysis_14_0.png" />
</div>
</div>
</section>
<section id="chaining-operations">
<h2>5.3.2 Chaining operations<a class="headerlink" href="#chaining-operations" title="Permalink to this headline">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">.update_sessions()</span></code> always returns a <strong>copy</strong> of the Fex object, so that you can <strong>chain</strong> operations together including existing pandas methods like <code class="docutils literal notranslate"><span class="pre">.plot()</span></code>. Here’s an example passing a dictionary to <code class="docutils literal notranslate"><span class="pre">.update_sessions()</span></code>, which maps between old and new session names:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Which condition each video belonged to
video2condition = dict(
    zip(
        clip_attrs[&quot;input&quot;].str.replace(&quot;.mp4&quot;, &quot;.csv&quot;, regex=False),
        clip_attrs[&quot;condition&quot;],
    )
)

# Update sesssions to group by condition, compute means (per condition), and make a
# barplot of the mean AUs for each condition
ax = (
    by_video.update_sessions(video2condition)
    .extract_mean()
    .aus.plot(kind=&quot;bar&quot;, legend=False, title=&quot;Mean AU detection by condition&quot;)
)
ax.set(ylabel=&#39;Average Probability&#39;, title=&#39;AU detection by condition&#39;, xticklabels=[&#39;Good News&#39;, &#39;Bad News&#39;]);
plt.xticks(rotation=0);
sns.despine();
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/05_fex_analysis_17_0.png" src="../_images/05_fex_analysis_17_0.png" />
</div>
</div>
<p>We can also focus in on the AUs associated with happiness:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>aus = [&quot;AU06&quot;, &quot;AU12&quot;, &quot;AU25&quot;]  # from https://py-feat.org/pages/au_reference.html

# Update the sessions to condition compute summary stats
summary = by_video.update_sessions(video2condition).extract_summary(
    mean=True, sem=True, std=False, min=False, max=False
)

# Organize them for plotting
bad_means = summary.loc[&quot;badNews&quot;, [f&quot;mean_{au}&quot; for au in aus]]
bad_sems = summary.loc[&quot;badNews&quot;, [f&quot;sem_{au}&quot; for au in aus]]
good_means = summary.loc[&quot;goodNews&quot;, [f&quot;mean_{au}&quot; for au in aus]]
good_sems = summary.loc[&quot;goodNews&quot;, [f&quot;sem_{au}&quot; for au in aus]]

# Plot
fig, ax = plt.subplots(figsize=(3, 4))
ind = np.arange(len(bad_means))
width = 0.35
rects1 = ax.bar(ind - width / 2, bad_means, width, yerr=bad_sems, label=&quot;Bad News&quot;);
rects2 = ax.bar(ind + width / 2, good_means, width, yerr=good_sems, label=&quot;Good News&quot;);
ax.set(ylabel=&quot;Average Probability&quot;, title=&quot;&quot;, xticks=ind, xticklabels=aus, ylim=(0, 1));
ax.legend(loc=&quot;upper left&quot;, frameon=False);
plt.axhline(0.5, ls=&quot;--&quot;, color=&quot;k&quot;);
sns.despine();
plt.xticks(rotation=45);
plt.tight_layout();
plt.savefig(&#39;./fig_maker/au_diffs.pdf&#39;, bbox_inches=&#39;tight&#39;);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/05_fex_analysis_19_0.png" src="../_images/05_fex_analysis_19_0.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="comparing-the-condition-difference-across-aus-using-regression">
<h1>5.4 Comparing the condition difference across AUs using regression<a class="headerlink" href="#comparing-the-condition-difference-across-aus-using-regression" title="Permalink to this headline">#</a></h1>
<p>One way we can compare what AUs in the plot show significant differences is by using the <code class="docutils literal notranslate"><span class="pre">.regress()</span></code> method along with numerical contrast codes. For example we can test the difference in activation of every AU when participants delivered <em>good</em> vs <em>bad</em> news.</p>
<p>This is analogous to the “mass-univariate” GLM approach in fMRI research, and allows us to identify what AUs are significantly more active in one condition vs another:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Save the by_condition fex from above
by_condition = video_means.update_sessions(video2condition)

# We set numerical contrasts to compare mean good news &gt; mean bad news
by_condition_codes = by_condition.update_sessions({&quot;goodNews&quot;: 1., &quot;badNews&quot;: -1})

# Now we perform a regression (t-test) at every AU
b, se, t, p, df, residuals = by_condition_codes.regress(
    X=&quot;sessions&quot;, y=&quot;aus&quot;, fit_intercept=True
)

# We can perform bonferroni correction for multiple comparisions:
p_bonf = p / p.shape[1]

results = pd.concat(
    [
        b.round(3).loc[[&quot;sessions&quot;]].rename(index={&quot;sessions&quot;: &quot;betas&quot;}),
        se.round(3).loc[[&quot;sessions&quot;]].rename(index={&quot;sessions&quot;: &quot;ses&quot;}),
        t.round(3).loc[[&quot;sessions&quot;]].rename(index={&quot;sessions&quot;: &quot;t-stats&quot;}),
        df.round(3).loc[[&quot;sessions&quot;]].rename(index={&quot;sessions&quot;: &quot;dof&quot;}),
        p_bonf.round(3).loc[[&quot;sessions&quot;]].rename(index={&quot;sessions&quot;: &quot;p-values&quot;}),
    ]
)

ax = results.loc[&quot;betas&quot;].plot(
    kind=&quot;bar&quot;,
    yerr=results.loc[&quot;ses&quot;],
    color=[
        &quot;steelblue&quot; if elem else &quot;gray&quot;
        for elem in results.loc[&quot;p-values&quot;] &lt; 0.01
    ],
    title=&quot;Good News &gt; Bad News\n(blue: p &lt; .01)&quot;,
);
xticks = ax.get_xticklabels();
xticks = [elem.get_text().split(&#39;_&#39;)[-1] for elem in xticks]
ax.set_xticklabels(xticks);
ax.set_ylabel(&#39;Beta +/- SE&#39;);
sns.despine();
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/05_fex_analysis_21_0.png" src="../_images/05_fex_analysis_21_0.png" />
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="decoding-condition-from-facial-features">
<h1>5.5 Decoding condition from facial features<a class="headerlink" href="#decoding-condition-from-facial-features" title="Permalink to this headline">#</a></h1>
<p>We can easily perform an analysis just like Watson et al, by training a LinearDiscriminantAnalysis (LDA) decoder to classify which condition a video came from based on average <strong>AU</strong> and <strong>headpose</strong> detections.</p>
<p>To do this we can use the <code class="docutils literal notranslate"><span class="pre">.predict()</span></code> which behaves just like <code class="docutils literal notranslate"><span class="pre">.regress()</span></code> but also requires a <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> <code class="docutils literal notranslate"><span class="pre">Estimator</span></code>. We can use keyword arguments to perform 10-fold cross-validation to test the accuracy of each decoder:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.preprocessing import (
    StandardScaler,
)  # always a good idea to normalize your features!
from sklearn.pipeline import make_pipeline

# List of different models we&#39;ll train
feature_list = [&quot;emotions&quot;, &quot;aus&quot;, &quot;poses&quot;, &quot;emotions,poses&quot;, &quot;aus,poses&quot;]
results = []
models = {}

for features in feature_list:

    # .predict is just like .regress, but this time session is our y.
    model, accuracy = by_condition.predict(
        X=features,
        y=&quot;sessions&quot;,
        model=make_pipeline(StandardScaler(), LinearDiscriminantAnalysis()),
        cv_kwargs={&quot;cv&quot;: 10},
    )

    # Save the model
    models[features] = model

    # Save the performance for plotting
    results.append(
        pd.DataFrame(
            {&quot;Accuracy&quot;: accuracy * 100, &quot;Features&quot;: [features] * len(accuracy)}
        )
    )
    # Print performance
    print(
        f&quot;{features} model accuracy: {accuracy.mean()*100:.3g}% +/- {accuracy.std()*100:.3g}%&quot;
    )

# Concat results into a single dataframe and tweak column names
results = pd.concat(results).assign(
    Features=lambda df: df.Features.map(
        {
            &quot;emotions&quot;: &quot;Emotions&quot;,
            &quot;poses&quot;: &quot;Pose&quot;,
            &quot;aus&quot;: &quot;AUs&quot;,
            &quot;emotions,poses&quot;: &quot;Emotions\n+ Pose&quot;,
            &quot;aus,poses&quot;: &quot;AUs+Pose&quot;,
        }
    )
)
# Plot it
# with sns.plotting_context(&quot;talk&quot;, font_scale=1.8):
f, ax = plt.subplots(1, 1, figsize=(3.75,4));
ax = sns.barplot(
    x=&quot;Features&quot;,
    y=&quot;Accuracy&quot;,
    errorbar=&quot;sd&quot;,
    dodge=False,
    hue=&quot;Features&quot;,
    data=results,
    ax=ax,
    order=[&quot;Emotions&quot;, &quot;Emotions\n+ Pose&quot;, &quot;AUs+Pose&quot;, &quot;AUs&quot;, &quot;Pose&quot;],
);
ax.get_legend().remove();
ax.set_title(&quot;Good News vs Bad News\nClassifier Performance&quot;);
ax.set(ylabel=&quot;Accuracy&quot;, xlabel=&quot;&quot;);
sns.despine();
plt.axhline(y=50, ls=&quot;--&quot;, color=&quot;k&quot;);
plt.xticks(rotation=90);
plt.tight_layout();

plt.savefig(&#39;./decoding_acc.pdf&#39;, bbox_inches=&#39;tight&#39;);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>emotions model accuracy: 100% +/- 0%
aus model accuracy: 85% +/- 22.9%
poses model accuracy: 80% +/- 33.2%
emotions,poses model accuracy: 95% +/- 15%
aus,poses model accuracy: 90% +/- 20%
</pre></div>
</div>
<img alt="../_images/05_fex_analysis_23_1.png" src="../_images/05_fex_analysis_23_1.png" />
</div>
</div>
<section id="visualizing-decoder-weights">
<h2>5.5.1 Visualizing decoder weights<a class="headerlink" href="#visualizing-decoder-weights" title="Permalink to this headline">#</a></h2>
<p>Using what we learned in the previous tutorial, we can visualize the coefficients for any models that used AU features. This allows us to “see” the underlying facial expression that the classifier learned!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from feat.plotting import plot_face

plot_face(
    au=models[&#39;aus&#39;][1].coef_.squeeze(), # the LDA coefs from the AUs pipeline model
    feature_range=(0, 1),
    muscles={&quot;all&quot;: &quot;heatmap&quot;},
    title=&quot;Expression reconstructed from\nAU classifier weights&quot;,
    title_kwargs={&#39;wrap&#39;:False}
);
sns.despine(left=True,bottom=True);

plt.savefig(&#39;./fig_maker/weights.pdf&#39;, bbox_inches=&#39;tight&#39;);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/05_fex_analysis_25_0.png" src="../_images/05_fex_analysis_25_0.png" />
</div>
</div>
<p>Even cooler we can <em>animate</em> that face expression to <strong>emphasize what’s changing.</strong> Here we start from a neutral face:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from feat.plotting import animate_face

animation = animate_face(
    end=models[&#39;aus&#39;][1].coef_.squeeze(), # same as before
    feature_range=(0, 1),
    muscles={&#39;all&#39;: &#39;heatmap&#39;},
    title=&quot;Good vs Bad News Classifier Weights&quot;,
    save=&quot;weights.gif&quot;,
)
</pre></div>
</div>
</div>
</div>
<p><img alt="" src="../_images/weights.gif" /></p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="time-series-analysis">
<h1>5.6 Time-series analysis<a class="headerlink" href="#time-series-analysis" title="Permalink to this headline">#</a></h1>
<p>Finally we might be interested in looking the similarity of the detected features <strong>over time</strong>. We can do that using the <code class="docutils literal notranslate"><span class="pre">.isc()</span></code> method which takes a column and metric to use. Here we compare detected happiness between all pairs of videos.</p>
<p>We use some helper functions to cluster, sort, and plot the correlation matrix. Warmer colors indicate a pair of videos elicited more <em>similar</em> detected Happiness over time. We see that some videos show high-correlation in-terms of their detected happiness over-time. This is likely why the classifier above was able to decode conditions so well.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># ISC returns a video x video pearson correlation matrix
isc = fex.isc(col = &quot;happiness&quot;, method=&#39;pearson&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def cluster_corrs(df):
    &quot;&quot;&quot;Helper to reorder rows and cols of correlation matrix based on clustering&quot;&quot;&quot;

    import scipy.cluster.hierarchy as sch

    pairwise_distances = sch.distance.pdist(df)
    linkage = sch.linkage(pairwise_distances, method=&quot;complete&quot;)
    cluster_distance_threshold = pairwise_distances.max() / 2
    idx_to_cluster_array = sch.fcluster(
        linkage, cluster_distance_threshold, criterion=&quot;distance&quot;
    )
    idx = np.argsort(idx_to_cluster_array)
    return df.iloc[idx, :].T.iloc[idx, :]

def add_cond_to_ticks(ax):
    &quot;&quot;&quot;Helper to add condition info to each tick label&quot;&quot;&quot;
    xlabels, ylabels = [], []
    for xlabel, ylabel in zip(ax.get_xticklabels(), ax.get_yticklabels()):
        x_condition = video2condition[xlabel.get_text()]
        y_condition = video2condition[ylabel.get_text()]
        x_new = f&quot;{x_condition[:-4]}_{xlabel.get_text().split(&#39;.csv&#39;)[0][1:]}&quot;
        y_new = f&quot;{y_condition[:-4]}_{ylabel.get_text().split(&#39;.csv&#39;)[0][1:]}&quot;
        xlabels.append(x_new)
        ylabels.append(y_new)

    ax.set_xticklabels(xlabels);
    ax.set_yticklabels(ylabels);
    return ax

# Plot it
ax = sns.heatmap(
    cluster_corrs(isc),
    cmap=&quot;RdBu_r&quot;,
    vmin=-1, vmax=1,
    square=True,
)

ax = add_cond_to_ticks(ax)

ax.set(xlabel=&quot;&quot;, ylabel=&quot;&quot;, title=&quot;Inter-video Happiness\ntimeseries correlation&quot;);
plt.savefig(&#39;./fig_maker/isc.pdf&#39;, bbox_inches=&#39;tight&#39;);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/05_fex_analysis_31_0.png" src="../_images/05_fex_analysis_31_0.png" />
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./basic_tutorials"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="04_plotting.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">4. Visualizing Facial Expressions</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../extra_tutorials/06_trainAUvisModel.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">6. Training an AU visualization model</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Eshin Jolly, Jin Hyun Cheong, Tiankang Xie, Luke J. Chang<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>