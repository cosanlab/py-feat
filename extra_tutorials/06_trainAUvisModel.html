
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>6. Training an AU visualization model &#8212; Py-Feat</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="7. Example labels and landmark dataset loading" href="07_extract_labels_and_landmarks.html" />
    <link rel="prev" title="5. Running a full analysis" href="../basic_tutorials/05_fex_analysis.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/pyfeat_logo_small.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Py-Feat</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../pages/intro.html">
                    Py-Feat: Python Facial Expression Analysis Toolbox
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting Started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../pages/installation.html">
   How to install Py-Feat
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pages/models.html">
   Included pre-trained detectors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pages/au_reference.html">
   Action Unit Reference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pages/usage_guide.html">
   Tips, Community, and Known Issues
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Basic Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../basic_tutorials/01_basics.html">
   1. Py-Feat basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../basic_tutorials/02_detector_imgs.html">
   2. Detecting facial expressions from images
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../basic_tutorials/03_detector_vids.html">
   3. Detecting facial expressions from videos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../basic_tutorials/04_plotting.html">
   4. Visualizing Facial Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../basic_tutorials/05_fex_analysis.html">
   5. Running a full analysis
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Advanced Tutorials
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   6. Training an AU visualization model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07_extract_labels_and_landmarks.html">
   7. Example labels and landmark dataset loading
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="08_train_hogs.html">
   8. Training HOG-based AU detectors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="09_test_bbox.html">
   9. Benchmarking Bounding Box using data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="10_test_lands.html">
   10. Benchmarking Landmark models using data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="11_test_Poseinfo.html">
   11. Benchmarking Pose detectors using data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="12_test_aus.html">
   12. Benchmarking Action Unit detector using data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="13_test_emos.html">
   13. Benchmarking pyfeat Emotion detection algorithms using data
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  API
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../pages/api.html">
   API Reference
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Contributing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../pages/contribute.html">
   General contributions guidelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pages/modelContribution.html">
   Contributing new detectors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pages/changelog.html">
   Change Log
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/cosanlab/py-feat">
   GitHub Repository
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/cosanlab/py-feat/master?urlpath=tree/notebooks/extra_tutorials/06_trainAUvisModel.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://jhub.dartmouth.edu/hub/user-redirect/git-pull?repo=https%3A//github.com/cosanlab/py-feat&urlpath=tree/py-feat/notebooks/extra_tutorials/06_trainAUvisModel.ipynb&branch=master"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on JupyterHub"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_jupyterhub.svg">
  </span>
<span class="headerbtn__text-container">JupyterHub</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/cosanlab/py-feat/blob/master/notebooks/extra_tutorials/06_trainAUvisModel.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/cosanlab/py-feat"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/cosanlab/py-feat/issues/new?title=Issue%20on%20page%20%2Fextra_tutorials/06_trainAUvisModel.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/extra_tutorials/06_trainAUvisModel.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imports-and-paths">
   Imports and Paths
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-clean-and-aggregate-extracted-labels-and-landmarks">
   Load, clean, and aggregate extracted labels and landmarks
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#balance-au-occurences-by-sub-sampling">
   Balance AU-occurences by sub-sampling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fit-plsregression-model">
   Fit PLSRegression model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#saving-and-loading-trained-model">
   Saving and loading trained model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualizing-detections-using-model">
   Visualizing detections using model
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>6. Training an AU visualization model</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imports-and-paths">
   Imports and Paths
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-clean-and-aggregate-extracted-labels-and-landmarks">
   Load, clean, and aggregate extracted labels and landmarks
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#balance-au-occurences-by-sub-sampling">
   Balance AU-occurences by sub-sampling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fit-plsregression-model">
   Fit PLSRegression model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#saving-and-loading-trained-model">
   Saving and loading trained model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualizing-detections-using-model">
   Visualizing detections using model
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="training-an-au-visualization-model">
<h1>6. Training an AU visualization model<a class="headerlink" href="#training-an-au-visualization-model" title="Permalink to this headline">#</a></h1>
<p><em>written by Eshin Jolly</em></p>
<p>This tutorial illustrates how we trained an AU visualization model in py-feat that can take a vector of AUs and output corresponding facial landmarks. This makes it possible to visualize facial expressions from AU detections by applying a learned transformation to a neutral template face.</p>
<p>To train the model we aggregate AU label and landmark data from the EmotioNet, DISFA Plus, and BP4d datasets. Detailed code on how to do that can be found in the <a class="reference internal" href="07_extract_labels_and_landmarks.html"><span class="doc std std-doc">extracting labels and landmarks notebook</span></a>. You’ll need to run the extraction once for each dataset before you can train the AU visualization model with the code presented here.</p>
<p>This tutorial assumes that the extracted csv files are in the <code class="docutils literal notranslate"><span class="pre">data/extracted_labels_landmarks</span></code> folder at the root of this repository. And that files are names as (lowercase) <code class="docutils literal notranslate"><span class="pre">[dataset]_labels.csv</span></code> and <code class="docutils literal notranslate"><span class="pre">[dataset]_landmarks.csv</span></code></p>
<p>If you’re adding new AU Detectors, it me useful to also include a visualization model for your specific detector, especially if the number or AU outputs differ from our included visualization model (20 AUs): 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 14, 15, 17, 20, 23, 24, 25, 26, 28, 43.</p>
<p>In <a class="reference external" href="#jaanet-visualization-model">this section</a> of the notebook you can see how we train a separate visualization model for the JAANET AU detector</p>
<section id="imports-and-paths">
<h2>Imports and Paths<a class="headerlink" href="#imports-and-paths" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import sys
import h5py
from feat.utils.io import get_resource_path
from feat.plotting import load_viz_model
from sklearn.model_selection import KFold
from sklearn.cross_decomposition import PLSRegression
from sklearn import __version__ as skversion
from joblib import dump
from pathlib import Path
from feat.pretrained import AU_LANDMARK_MAP
from typing import List, Union, Tuple

sns.set_style(&quot;white&quot;)

# Set data directory to data folder relative to location of this notebook
here = Path(os.path.realpath(&quot;&quot;))
base_dir = here.parent.parent
data_dir = base_dir / &quot;data&quot; / &quot;extracted_labels_landmarks&quot;

# Get the 20 AUs we use for training the model
au_cols = AU_LANDMARK_MAP[&quot;Feat&quot;]
print(f&quot;Using {len(au_cols)} AUs&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Using 20 AUs
</pre></div>
</div>
</div>
</div>
</section>
<section id="load-clean-and-aggregate-extracted-labels-and-landmarks">
<h2>Load, clean, and aggregate extracted labels and landmarks<a class="headerlink" href="#load-clean-and-aggregate-extracted-labels-and-landmarks" title="Permalink to this headline">#</a></h2>
<p>First we load up the 3 datasets containing AU labels and facial landmarks and concatenate them into 2 dataframes. All AU values are also rescaled to 0-1 indicating the <em>presence</em> of an AU for that sample.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def load_landmark_au_data(
    au_cols: List, verbose: bool = True, concat: bool = True
) -&gt; Union[Tuple[pd.DataFrame, pd.DataFrame], Tuple[List, List]]:

    &quot;&quot;&quot;Load and concatenate the emotionet, difsaplus, and bp4d datasets&quot;&quot;&quot;

    labels, landmarks = [], []
    for name in [&quot;emotionet&quot;, &quot;disfaplus&quot;, &quot;bp4d&quot;]:

        labels_file, landmarks_file = f&quot;{name}_labels.csv&quot;, f&quot;{name}_landmarks.csv&quot;

        labels_df = (
            pd.read_csv(data_dir / labels_file)
            .replace({999: np.nan, 9: np.nan})
            .drop(columns=[&quot;URL&quot;], errors=&quot;ignore&quot;)
            .pipe(lambda df: df.astype(&quot;float&quot;) / 5 if name == &quot;disfaplus&quot; else df)
            .fillna(0)
        )
        if verbose:
            print(f&quot;{name}: {labels_df.shape[0]}&quot;)
        labels.append(labels_df)
        landmarks_df = pd.read_csv(os.path.join(data_dir, landmarks_file))
        landmarks.append(landmarks_df)

    if concat:
        labels = pd.concat(labels, axis=0, ignore_index=True)[au_cols].fillna(0)
        landmarks = pd.concat(landmarks, axis=0, ignore_index=True).fillna(0)
    else:
        labels = list(map(lambda df: df.fillna(0), labels))
        landmarks = list(map(lambda df: df.fillna(0), landmarks))

    if verbose and concat:
        print(f&quot;Aggregated landmarks: {landmarks.shape}&quot;)
        print(f&quot;Aggregated labels: {labels.shape}&quot;)

    return labels, landmarks
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>labels, landmarks = load_landmark_au_data(au_cols=au_cols)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>emotionet: 24587
disfaplus: 57668
bp4d: 143951
Aggregated landmarks: (226206, 136)
Aggregated labels: (226206, 20)
</pre></div>
</div>
</div>
</div>
<p>We can examine the correlation between AU occurences across all the datasets to get a sense of what AU’s tend to co-occur:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>ax = sns.heatmap(labels.corr(), cmap=&#39;bwr&#39;, vmin=-1, vmax=1)
_ = ax.set(title=&#39;Aggregated AU Correlations&#39;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/06_trainAUvisModel_8_0.png" src="../_images/06_trainAUvisModel_8_0.png" />
</div>
</div>
<p>However, due to differences in the AUs included in each dataset, these correlations vary:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>labels_list, landmarks_list = load_landmark_au_data(au_cols=au_cols, concat=False, verbose=False)

for label, name in zip(labels_list, [&#39;emotionet&#39;, &#39;disfaplus&#39;, &#39;bp4d&#39;]):
    f, ax = plt.subplots(1,1)
    ax = sns.heatmap(label.corr(), cmap=&#39;bwr&#39;, vmin=-1, vmax=1, ax=ax)
    _ = ax.set(title=f&quot;{name} AU correlations&quot;)
    
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/06_trainAUvisModel_10_0.png" src="../_images/06_trainAUvisModel_10_0.png" />
<img alt="../_images/06_trainAUvisModel_10_1.png" src="../_images/06_trainAUvisModel_10_1.png" />
<img alt="../_images/06_trainAUvisModel_10_2.png" src="../_images/06_trainAUvisModel_10_2.png" />
</div>
</div>
</section>
<section id="balance-au-occurences-by-sub-sampling">
<h2>Balance AU-occurences by sub-sampling<a class="headerlink" href="#balance-au-occurences-by-sub-sampling" title="Permalink to this headline">#</a></h2>
<p>Because datasets differ in which AUs they contain and because AUs differ greatly in their occurence across samples, we sub-sample the aggregated data to generate a new dataset that contains at least 650 occurences of each AU. This number was chosen because it is the largest number of positive samples (samples where the AU was present) for the AU with the fewest positive samples (AU43). This helps balance the features out a bit:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def pseudo_balance_au_occurences(
    labels, au_cols, min_pos_sample=650, verbose=True, random_state=0
):
    &quot;&quot;&quot;Sub-sample the labels dataframe so for each AU at least min_pos_sample rows
    contain an instance of that AU. This will generate a new dataset of shape
    min_pos_sample * len(au_cols) x len(au_cols)&quot;&quot;&quot;
    if min_pos_sample &gt; labels.sum().min():
        raise ValueError(f&quot;min_pos_sample must be {labels.sum().min()} or lower&quot;)

    if verbose:
        print(&quot;Pseudo balancing samples&quot;)
    balY = pd.DataFrame()
    balX = pd.DataFrame()
    for AU in labels[au_cols].columns:
        if np.sum(labels[AU] == 1) &gt; min_pos_sample:
            replace = False
        else:
            replace = True
        newSample = labels[labels[AU] &gt; 0.5].sample(
            min_pos_sample, replace=replace, random_state=random_state
        )
        balX = pd.concat([balX, newSample])
        balY = pd.concat([balY, landmarks.loc[newSample.index]])

    # Make sure we have more occurrences of each AU than in the original dataset
    assert all(balX.mean() &gt; labels.mean())

    return balX, balY
</pre></div>
</div>
</div>
</div>
<p>This gives us a new dataset of shape:<br />
(650 * 20) x 20</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Random-state for reproducibility
balX, balY = pseudo_balance_au_occurences(
    labels, au_cols, min_pos_sample=650, random_state=0
)
print(f&quot;Resampled dataset shape: {balX.shape}&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pseudo balancing samples
Resampled dataset shape: (13000, 20)
</pre></div>
</div>
</div>
</div>
<p>We can see that our resampled dataset contains signficantly higher proportions of each AU, which will make it a bit easier to train the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>ax = labels.mean().plot(kind=&quot;bar&quot;, label=&quot;original&quot;)
ax = balX.mean().plot(
    kind=&quot;bar&quot;, color=&quot;orange&quot;, alpha=0.5, ax=ax, label=&quot;pseudo-balanced&quot;
)
_ = ax.legend()
_ = ax.set(ylabel=&#39;Proportion of Samples with AU present&#39;)
sns.despine()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/06_trainAUvisModel_16_0.png" src="../_images/06_trainAUvisModel_16_0.png" />
</div>
</div>
</section>
<section id="fit-plsregression-model">
<h2>Fit PLSRegression model<a class="headerlink" href="#fit-plsregression-model" title="Permalink to this headline">#</a></h2>
<p>Finally we can train a partial-least-squares regression model to map between AUs and facial landmarks. We first align facial landmarks to a template <em>neutral expression</em> face. This will allow us to use the regression weights to “warp” this face to display various expressions. To validate our model, we test predictive performance out-of-sample using 3-fold cross-validation. We also return the overall-fit across the full (resampled) data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def preprocess_features(
    X, Y, align_landmarks_to_neutral=True, scale_across_features=False, poly_degree=1
):
    &quot;&quot;&quot;Take dataframes of labels and landmarks and prepare them for PLSRegression estimator&quot;&quot;&quot;
    from feat.utils.image_operations import registration, neutral
    from sklearn.preprocessing import scale

    _X = X.to_numpy()

    # We can optionally add more features prior to model fitting by creating new columns
    # that capture the interactions between 2, 3, or more AUs via polynomial terms
    # This might help model performance, at the cost of over-fitting so feel free to
    # play around with this. 
    # We don&#39;t include any polynomial terms by default
    if poly_degree &gt; 1:
        from sklearn.preprocessing import PolynomialFeatures

        poly = PolynomialFeatures(
            degree=poly_degree, interaction_only=True, include_bias=False
        )
        _X = poly.fit_transform(_X)

    # It can also be helpful to scale AUs within each sample such that they reflect
    # z-scores relative to the mean/std AU occurences within that sample, rather than
    # values between 0-1. This can be helpful if you use a polynomial degree &gt; 1
    # But we don&#39;t do this by default
    if scale_across_features:
        _X = scale(_X, axis=1)

    _Y = Y.to_numpy()

    if align_landmarks_to_neutral:
        _Y = registration(_Y, neutral)

    print(f&quot;Data shape: {_X.shape}\n&quot;)
    return _X, _Y


def fit_pls(
    X,
    Y,
    n_splits=3,
    refit_full=True,
    n_components=20,
    max_iter=2000,
):
    &quot;&quot;&quot;Fit and validate a PLSRegression model&quot;&quot;&quot;

    outstr = f&quot;Components: {n_components}\n&quot;

    if n_splits is not None:
        kf = KFold(n_splits=n_splits)
        scores = []
        for train_index, test_index in kf.split(X):
            X_train, X_test = X[train_index], X[test_index]
            y_train, y_test = Y[train_index], Y[test_index]
            clf = PLSRegression(n_components=n_components, max_iter=max_iter)
            _ = clf.fit(X_train, y_train)
            scores.append(clf.score(X_test, y_test))

        outstr += f&quot;Test R^2 ({n_splits}-fold): {np.round(np.mean(scores),3)}&quot;

    clf = None
    if refit_full:
        clf = PLSRegression(n_components=n_components, max_iter=2000)
        _ = clf.fit(X, Y)
        outstr += f&quot;\tFull R^2: {np.round(clf.score(X, Y), 3)}\n&quot;

    print(outstr)
    return clf

</pre></div>
</div>
</div>
</div>
<p>We can start by examiningd how changing the amount of dimensionality-reduction (number of PLS components) affect the model performance using just original 20d AUs:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>X, Y = preprocess_features(balX,balY)

clf = fit_pls(X, Y, n_components=len(au_cols))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data shape: (13000, 20)

Components: 20
Test R^2 (3-fold): 0.12	Full R^2: 0.155
</pre></div>
</div>
</div>
</div>
</section>
<section id="saving-and-loading-trained-model">
<h2>Saving and loading trained model<a class="headerlink" href="#saving-and-loading-trained-model" title="Permalink to this headline">#</a></h2>
<p>We save and package the trained visualization model in two ways:</p>
<ol class="simple">
<li><p>Using <code class="docutils literal notranslate"><span class="pre">joblib.dump</span></code> as recommended by the <a class="reference external" href="https://scikit-learn.org/stable/modules/model_persistence.html">sklearn docs</a>. This is the default model that gets loaded if your installed Python and sklearn <code class="docutils literal notranslate"><span class="pre">major.minor</span></code> versions match those the model was originally trained with</p></li>
<li><p>As an HDF5 file with the necessary attributes to initialize a new <code class="docutils literal notranslate"><span class="pre">PLSRegression</span></code> object on any system. This is the fallback that gets loaded if your installed Python and sklearn <code class="docutils literal notranslate"><span class="pre">major.minor</span></code> versions don’t match what the model was originally trained with</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def save_viz_model(model_name, clf):

    # Add some extra attributes to the model instance and dump it
    clf.X_train = X
    clf.Y_train = Y
    clf.skversion = skversion
    clf.pyversion = sys.version
    clf.model_name_ = model_name
    _ = dump(clf, os.path.join(get_resource_path(), f&quot;{model_name}.joblib&quot;))

    # Do the same as an hdf5 file
    hf = h5py.File(os.path.join(get_resource_path(), f&quot;{model_name}.h5&quot;), &quot;w&quot;)
    _ = hf.create_dataset(&quot;coef&quot;, data=clf.coef_)
    _ = hf.create_dataset(&quot;x_weights&quot;, data=clf.x_weights_)
    _ = hf.create_dataset(&quot;x_mean&quot;, data=clf._x_mean)
    _ = hf.create_dataset(&quot;y_mean&quot;, data=clf._y_mean)
    _ = hf.create_dataset(&quot;x_std&quot;, data=clf._x_std)
    _ = hf.create_dataset(&quot;y_std&quot;, data=clf._y_std)
    _ = hf.create_dataset(&quot;y_weights&quot;, data=clf.y_weights_)
    _ = hf.create_dataset(&quot;x_loadings&quot;, data=clf.x_loadings_)
    _ = hf.create_dataset(&quot;y_loadings&quot;, data=clf.y_loadings_)
    _ = hf.create_dataset(&quot;x_scores&quot;, data=clf.x_scores_)
    _ = hf.create_dataset(&quot;y_scores&quot;, data=clf.y_scores_)
    _ = hf.create_dataset(&quot;x_rotations&quot;, data=clf.x_rotations_)
    _ = hf.create_dataset(&quot;y_rotations&quot;, data=clf.y_rotations_)
    _ = hf.create_dataset(&quot;intercept&quot;, data=clf.intercept_)
    _ = hf.create_dataset(&quot;x_train&quot;, data=clf.X_train)
    _ = hf.create_dataset(&quot;y_train&quot;, data=clf.Y_train)
    hf.attrs[&quot;skversion&quot;] = clf.skversion
    hf.attrs[&quot;pyversion&quot;] = clf.pyversion
    hf.attrs[&quot;model_name&quot;] = clf.model_name_
    hf.close()
    print(&quot;Model saved!&quot;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>save_viz_model(&quot;pyfeat_aus_to_landmarks&quot;, clf)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model saved!
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/Esh/anaconda3/envs/py-feat/lib/python3.8/site-packages/sklearn/cross_decomposition/_pls.py:507: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).
  warnings.warn(
</pre></div>
</div>
</div>
</div>
<p>Now we can use the <code class="docutils literal notranslate"><span class="pre">load_viz_model</span></code> from <code class="docutils literal notranslate"><span class="pre">feat.utils</span></code> to try loading our model. This function will try to load a <code class="docutils literal notranslate"><span class="pre">.joblib</span></code> file if your major.minor version of sci-kit learn match those that the model was originally trained with. Otherwise it will fallback to loading a <code class="docutils literal notranslate"><span class="pre">.h5</span></code> file and reconstructing the estimator attributes.</p>
<p>If you don’t pass in a model name, the model we just trained is what gets loaded by default:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>loaded_model = load_viz_model(&#39;pyfeat_aus_to_landmarks&#39;, verbose=True)
loaded_model
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Loading joblib
</pre></div>
</div>
<div class="output text_html"><style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>PLSRegression(max_iter=2000, n_components=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">PLSRegression</label><div class="sk-toggleable__content"><pre>PLSRegression(max_iter=2000, n_components=20)</pre></div></div></div></div></div></div></div>
</div>
<p>We can make sure the loaded trained models are the same by comparing their learned coefficients and their performance on the aggregated data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>loaded_model.score(X,Y) == clf.score(X,Y)
np.allclose(loaded_model.coef_, clf.coef_)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/Esh/anaconda3/envs/py-feat/lib/python3.8/site-packages/sklearn/cross_decomposition/_pls.py:507: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).
  warnings.warn(
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualizing-detections-using-model">
<h2>Visualizing detections using model<a class="headerlink" href="#visualizing-detections-using-model" title="Permalink to this headline">#</a></h2>
<p>Now you can visualize AU detections by passing setting <code class="docutils literal notranslate"><span class="pre">faces='aus'</span></code> to the <code class="docutils literal notranslate"><span class="pre">.plot_detections()</span></code> method of a <code class="docutils literal notranslate"><span class="pre">Fex</span></code> dataclass:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from feat import Detector
from feat.utils.io import get_test_data_path

single_face_img_path = os.path.join(get_test_data_path(), &quot;single_face.jpg&quot;)

# Both the svm and logistic au models will use our visualization model
detector = Detector()

single_face_prediction = detector.detect_image(single_face_img_path)
figs = single_face_prediction.plot_detections(faces= &#39;aus&#39;, add_titles=False)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 1/1 [00:03&lt;00:00,  3.71s/it]
</pre></div>
</div>
<img alt="../_images/06_trainAUvisModel_30_1.png" src="../_images/06_trainAUvisModel_30_1.png" />
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./extra_tutorials"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../basic_tutorials/05_fex_analysis.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">5. Running a full analysis</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="07_extract_labels_and_landmarks.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">7. Example labels and landmark dataset loading</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Eshin Jolly, Jin Hyun Cheong, Tiankang Xie, Luke J. Chang<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>