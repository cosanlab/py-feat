
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Included pre-trained detectors &#8212; Py-Feat</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Action Unit Reference" href="au_reference.html" />
    <link rel="prev" title="How to install Py-Feat" href="installation.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/pyfeat_logo_small.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Py-Feat</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Py-Feat: Python Facial Expression Analysis Toolbox
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting Started
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="installation.html">
   How to install Py-Feat
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Included pre-trained detectors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="au_reference.html">
   Action Unit Reference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="usage_guide.html">
   Tips, Community, and Known Issues
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Basic Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../basic_tutorials/01_basics.html">
   1. Py-Feat basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../basic_tutorials/02_detector_imgs.html">
   2. Detecting facial expressions from images
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../basic_tutorials/03_detector_vids.html">
   3. Detecting facial expressions from videos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../basic_tutorials/04_plotting.html">
   4. Visualizing Facial Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../basic_tutorials/05_fex_analysis.html">
   5. Running a full analysis
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Advanced Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../extra_tutorials/06_trainAUvisModel.html">
   6. Training an AU visualization model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../extra_tutorials/07_extract_labels_and_landmarks.html">
   7. Example labels and landmark dataset loading
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../extra_tutorials/08_train_hogs.html">
   8. Training HOG-based AU detectors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../extra_tutorials/09_test_bbox.html">
   9. Benchmarking Bounding Box using data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../extra_tutorials/10_test_lands.html">
   10. Benchmarking Landmark models using data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../extra_tutorials/11_test_Poseinfo.html">
   11. Benchmarking Pose detectors using data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../extra_tutorials/12_test_aus.html">
   12. Benchmarking Action Unit detector using data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../extra_tutorials/13_test_emos.html">
   13. Benchmarking pyfeat Emotion detection algorithms using data
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  API
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="api.html">
   API Reference
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Contributing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="contribute.html">
   General contributions guidelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="modelContribution.html">
   Contributing new detectors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="changelog.html">
   Change Log
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/cosanlab/py-feat">
   GitHub Repository
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/cosanlab/py-feat"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/cosanlab/py-feat/issues/new?title=Issue%20on%20page%20%2Fpages/models.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/pages/models.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#face-detection">
   Face detection
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#facial-landmark-detection">
   Facial landmark detection
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#facial-pose-estimation">
   Facial Pose estimation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#action-unit-detection">
   Action Unit detection
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#emotion-detection">
   Emotion detection
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Included pre-trained detectors</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#face-detection">
   Face detection
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#facial-landmark-detection">
   Facial landmark detection
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#facial-pose-estimation">
   Facial Pose estimation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#action-unit-detection">
   Action Unit detection
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#emotion-detection">
   Emotion detection
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="included-pre-trained-detectors">
<h1>Included pre-trained detectors<a class="headerlink" href="#included-pre-trained-detectors" title="Permalink to this headline">#</a></h1>
<p>Below is a list of detectors included in Py-Feat and ready to use. The model names are in the titles followed by the reference publications. Bolded models are defaults.</p>
<p>You can specify any of these models for use in the <code class="docutils literal notranslate"><span class="pre">Detector</span></code> class by passing in the name as a string, e.g.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">feat</span> <span class="kn">import</span> <span class="n">Detector</span>

<span class="n">detector</span> <span class="o">=</span> <span class="n">Detector</span><span class="p">(</span><span class="n">emotion_model</span><span class="o">=</span><span class="s1">&#39;svm&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Models names are case-insensitive: <code class="docutils literal notranslate"><span class="pre">'resmasknet'</span> <span class="pre">==</span> <span class="pre">'ResMaskNet'</span></code></p>
</div>
<section id="face-detection">
<h2>Face detection<a class="headerlink" href="#face-detection" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">retinaface</span></code>: Single-stage dense face localisation</strong> in the wild by (<a class="reference external" href="https://arxiv.org/pdf/1905.00641v2.pdf">Deng et al., 2019</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mtcnn</span></code>: Multi-task cascaded convolutional networks by (<a class="reference external" href="https://arxiv.org/pdf/1604.02878.pdf">Zhang et al., 2016</a>; <a class="reference external" href="https://ieeexplore.ieee.org/document/9239720">Zhang et al., 2020</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">faceboxes</span></code>: A CPU real-time face detector with high accuracy by (<a class="reference external" href="https://arxiv.org/pdf/1708.05234v4.pdf">Zhang et al., 2018</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">img2pose</span></code>: Face Alignment and Detection via 6DoF, Face Pose Estimation (<a class="reference external" href="https://arxiv.org/pdf/2012.07791v2.pdf">Albiero et al., 2020</a>). Performs simultaneous (one-shot) face detection and head pose estimation</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">img2pose-c</span></code>: A ‘constrained’ version of the above model, fine-tuned on images of frontal faces with pitch, roll, yaw measures in the range of (-90, 90) degrees. Shows lesser performance on difficult face detection tasks, but state-of-the-art performance on face pose estimation for frontal faces</p></li>
</ul>
</section>
<section id="facial-landmark-detection">
<h2>Facial landmark detection<a class="headerlink" href="#facial-landmark-detection" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">mobilefacenet</span></code>: Efficient CNNs for accurate real time face verification on mobile devices</strong> (<a class="reference external" href="https://arxiv.org/ftp/arxiv/papers/1804/1804.07573.pdf">Chen et al, 2018</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mobilenet</span></code>: Efficient convolutional neural networks for mobile vision applications (<a class="reference external" href="https://arxiv.org/pdf/1704.04861v1.pdf">Howard et al, 2017</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pfld</span></code>: Practical Facial Landmark Detector by (<a class="reference external" href="https://arxiv.org/pdf/1902.10859.pdf">Guo et al, 2019</a>)</p></li>
</ul>
</section>
<section id="facial-pose-estimation">
<h2>Facial Pose estimation<a class="headerlink" href="#facial-pose-estimation" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">img2pose</span></code>: Face Alignment and Detection via 6DoF, Face Pose Estimation</strong> (<a class="reference external" href="https://arxiv.org/pdf/2012.07791v2.pdf">Albiero et al., 2020</a>). Performs simultaneous (one-shot) face detection and head pose estimation</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">img2pose-c</span></code>: A ‘constrained’ version of the above model, fine-tuned on images of frontal faces with pitch, roll, yaw measures in the range of (-90, 90) degrees. Shows lesser performance on hard face detection tasks, but state-of-the-art performance on head pose estimation for frontal faces.</p></li>
</ul>
</section>
<section id="action-unit-detection">
<h2>Action Unit detection<a class="headerlink" href="#action-unit-detection" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">xgb</span></code>: XGBoost Classifier model trained on Histogram of Oriented Gradients*</strong> extracted from BP4D, DISFA, CK+, UNBC-McMaster shoulder pain, and AFF-Wild2 datasets</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">svm</span></code>: SVM model trained on Histogram of Oriented Gradients** extracted from BP4D, DISFA, CK+, UNBC-McMaster shoulder pain, and AFF-Wild2 datasets</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>*For AU07, our <code class="docutils literal notranslate"><span class="pre">xbg</span></code> detector was trained with hinge-loss instead of cross-entropy loss like other AUs as this yielded substantially better detection peformance given the labeled data available for this AU. This means that while it returns continuous probability predictions,  these are more likely to appear binary in practice (i.e. be 0 or 1) and should be interpreted as <em>proportion of decision-trees with a detection</em> rather than <em>average decision-tree confidence</em> like other AU values.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>** Our <code class="docutils literal notranslate"><span class="pre">svm</span></code> detector uses the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC"><code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code></a> implementation from <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> and thus returns <strong>binary values</strong> for each AU rather than probabilities. If your use-case requires continuous-valued detections, we recommend the <code class="docutils literal notranslate"><span class="pre">xgb</span></code> detector instead.</p>
</div>
</section>
<section id="emotion-detection">
<h2>Emotion detection<a class="headerlink" href="#emotion-detection" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">resmasknet</span></code>: Facial expression recognition using residual masking network</strong> by (<a class="reference external" href="https://ieeexplore.ieee.org/document/9411919">Pham et al., 2020</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">svm</span></code>: SVM model trained on Histogram of Oriented Gradients extracted from ExpW, CK+, and JAFFE datasets</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./pages"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="installation.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">How to install Py-Feat</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="au_reference.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Action Unit Reference</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Eshin Jolly, Jin Hyun Cheong, Tiankang Xie, Luke J. Chang<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>